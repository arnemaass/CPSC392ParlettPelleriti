{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# data imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from plotnine import *\n",
    "\n",
    "# modeling imports\n",
    "from sklearn.linear_model import LinearRegression # Linear Regression Model\n",
    "from sklearn.preprocessing import StandardScaler #Z-score variables\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_percentage_error, mean_absolute_error #model evaluation\n",
    "\n",
    "\n",
    "# pipeline imports\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.compose import make_column_transformer\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Together\n",
    "\n",
    "## Linear Regression\n",
    "\n",
    "Remember that *linear* regression fits straight lines (or flat planes/hyperplanes with multiple predictors) using the formula $Y = mx + b$. If the relationship between the predictor and the outcome is not linear, then the model may not perform well. And more importantly, it will likely perform badly SPECIFICALLY for certain ranges of values. Think about an example where it might be especially problematic for our model to be worse at predicting (and/or consistently under or over predicts) for certain ranges of predictors?\n",
    "\n",
    "$$\\underbrace{Y_i}_\\text{Observed Value for Person i} = \\underbrace{\\beta_0}_\\text{intercept} + \\underbrace{\\beta_1}_\\text{Coefficient for X1} * \\underbrace{X_{i1}}_\\text{Value for person i on Variable X1} + ... + \\beta_p * X_{ip}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## How to Choose Model Parameters\n",
    "\n",
    "Linear Regression Models have two kinds of parameters: coefficients (which communicate the effect on the predicted value when increasing your predictors), and an intercept (the predicted value when all your predictors are 0). We need to choose these parameters so our model does as well as possible. We discussed two different methods for Linear Regression: Least Squares and Maximum Likelihood Estimation (MLE).\n",
    "\n",
    "### Least Squares\n",
    "As the name implies, Least Squares aims to choose parameter values that *minimize* the sum of squared errors. \n",
    "\n",
    "$$ \\text{SSE} = \\sum_{i = 1}^n(y_i - \\beta_0 - \\beta_1*x_i)^2 $$\n",
    "\n",
    "the $\\hat{y_i}$ represents our model's *predicted* value of $y_i$. For a simple linear regression with only 1 predictor, we get our prediction using the formula:\n",
    "\n",
    "$$ \\hat{y} = \\beta_0 + \\beta_1*x_i $$\n",
    "\n",
    "So let's plug that in for $\\hat{y_i}$:\n",
    "\n",
    "$$ \\text{SSE} = \\sum_{i = 1}^n(y_i - \\beta_0 - \\beta_1*x_i)^2 $$\n",
    "\n",
    "Now all we need to do is set the *partial derivatives* of the $\\text{SSE}$ to 0 and solve. The formula above has *two* parameters that we're interested in: $\\beta_0$ and $\\beta_1$, so we'll take the partial derivatives of $\\text{SSE}$ with respect to each of them:\n",
    "\n",
    "$$\\frac{\\partial SSE}{\\partial \\beta_0} = \\sum_{i = 1}^n 2(y_i - \\beta_0 - \\beta_1*x_i)(-1)$$\n",
    "$$\\frac{\\partial SSE}{\\partial \\beta_1} = \\sum_{i = 1}^n 2(y_i - \\beta_0 - \\beta_1*x_i)(-x_i)$$\n",
    "\n",
    "and set them equal to 0.\n",
    "\n",
    "$$\\frac{\\partial SSE}{\\partial \\beta_0} = \\sum_{i = 1}^n 2(y_i - \\beta_0 - \\beta_1*x_i)(-1) = 0$$\n",
    "$$\\frac{\\partial SSE}{\\partial \\beta_1} = \\sum_{i = 1}^n 2(y_i - \\beta_0 - \\beta_1*x_i)(-x_i) = 0$$\n",
    "\n",
    "then we solve for $\\beta_0$ and $\\beta_1$ and we get:\n",
    "\n",
    "$$\\beta_0 = \\bar{y} - \\hat{\\beta_1}* \\bar{x}$$\n",
    "\n",
    "and\n",
    "\n",
    "$$ \\beta_1 = \\frac{Cov(x,y)}{Var(x)} = Corr(x,y) * \\frac{sd(x)}{sd(y)} $$\n",
    "\n",
    "These values for $\\beta_0$ and $\\beta_1$ are the ones that *minimize* our Sum of Squared Errors ($\\text{SSE}$) and therefore give us a model that performs very well.\n",
    "\n",
    "### Maximum Likelihood Estimation\n",
    "\n",
    "Another way to choose the parameters (coefficients and intercept) of a Linear Regression model is Maximum Likelihood estimation, which we'll use a few other places in this course. Maximum Likelihood Estimation chooses parameters based on how *likely* they make the training data. Remember that a model is a description of the world. If we have a model that makes it *incredibly unlikely* that we'd see data that looks like our training data, that model might not be a good description of our world. \n",
    "\n",
    "The **likelihood** of an individual data point in our model is:\n",
    "\n",
    "$$ p(y_i | x_i; \\beta_0, \\beta_1, \\sigma^2) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-\\frac{(y_i - (\\beta_0 + \\beta_1 * x_i))^2}{2\\sigma^2}}$$\n",
    "\n",
    "$^\\text{(notice that the numerator in the exponent is just the squared error for that data point)}$\n",
    "\n",
    "If we have *multiple* data points in our training data, we'll *multiply* their likelihoods.\n",
    "\n",
    "$$ \\prod_{i = 1}^{n} p(y_i | x_i; \\beta_0, \\beta_1, \\sigma^2) = \\prod_{i = 1}^{n}\\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-\\frac{(y_i - (\\beta_0 + \\beta_1 * x_i))^2}{2\\sigma^2}}$$\n",
    "\n",
    "this gives us the overall likelihood of our training data *given* the values of $\\beta_0$, $\\beta_1$. We want to choose values of $\\beta_0$ and $\\beta_1$ that *maximize* the likelihood from the equation above. To do so, we typically take the *log* of the likelihood (remember logs turn multiplications into sums, which makes the math easier) and maximize *that* by setting it's partial derivatives (w.r.t $\\beta_0$ and $\\beta_1$) equal to 0.\n",
    "\n",
    "When we do that, it turns out we get the EXACT SAME estimates as from least squares!\n",
    "\n",
    "$$\\beta_0 = \\bar{y} - \\hat{\\beta_1}* \\bar{x}$$\n",
    "\n",
    "and\n",
    "\n",
    "$$ \\beta_1 = \\frac{Cov(x,y)}{Var(x)} = Corr(x,y) * \\frac{sd(x)}{sd(y)} $$\n",
    "\n",
    "These values for $\\beta_0$ and $\\beta_1$ are the ones that *mazimize* the likelihood of our data, and therefore give us a model that performs very well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Sklearn\n",
    "Sklearn has a really consistent and elegant workflow for almost all the predictive models they have. \n",
    "\n",
    "1. Separate your data into X (predictors) and y (outcome), and maybe do some model validation set up.\n",
    "2. Create an Empty Model.\n",
    "3. call `.fit()` using your training data\n",
    "4. call `.predict()` on ANY X data to get the model prediction for that data.\n",
    "5. Assess the model\n",
    "\n",
    "This workflow is relatively consistent throughout all the supervised/predictive models we learn, we'll just swap out the empty model.\n",
    "\n",
    "\n",
    "### Read and Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load amazon data\n",
    "# file is TAB separated, not COMMA separated (csv) so we use the sep = \"\\t\" argument\n",
    "ama = pd.read_csv(\"https://raw.githubusercontent.com/cmparlettpelleriti/CPSC392ParlettPelleriti/master/Data/amazon-books.txt\",\n",
    "                 sep = \"\\t\")\n",
    "ama.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check null\n",
    "ama.isnull().sum()\n",
    "# ama.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop missing\n",
    "ama.dropna(inplace = True)\n",
    "ama.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate your data into `X` (predictors) and `y` (outcome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up X and y\n",
    "predictors = [\"List Price\", \"NumPages\", \"Weight (oz)\", \"Thick\", \"Height\", \"Width\"]\n",
    "\n",
    "X = ama[predictors]\n",
    "y = ama[\"Amazon Price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z score\n",
    "z = make_column_transformer((StandardScaler(), predictors),\n",
    "                            remainder = \"passthrough\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an Empty Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "\n",
    "pipe = Pipeline([(\"zscore\", z),\n",
    "                (\"linearregression\", lr)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `.fit()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `.predict()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipe.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assess the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"MSE : \", mean_squared_error(y,y_pred))\n",
    "print(\"MAE : \", mean_absolute_error(y,y_pred))\n",
    "print(\"MAPE: \", mean_squared_error(y,y_pred))\n",
    "print(\"R2  : \", r2_score(y,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking Assumptions\n",
    "\n",
    "Remember there are 3 main assumptions$^*$ of Linear Regression:\n",
    "\n",
    "- Linearity\n",
    "- Homoskedasticity\n",
    "- Normality of Errors\n",
    "\n",
    "\n",
    "$^*$ There's also an assumption of *Independence*, aka that the value of one data point does not affect the value of another data point.\n",
    "\n",
    "\n",
    "### Linearity\n",
    "\n",
    "We assess linearity by either:\n",
    "\n",
    "- plotting one predictor at a time against the outcome, and see if there are any clear non-linear patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for c in predictors:\n",
    "#     t = \"Amazon Price vs. \" + c\n",
    "#     print(ggplot(ama, aes(x = c, y = \"Amazon Price\")) + \n",
    "#      geom_point() + \n",
    "#      theme_minimal() + \n",
    "#      labs(title = t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- plot the predicted values (x-axis) by the residuals (y-axis) and look for clear non-linear patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assump = pd.DataFrame({\"errors\": y - y_pred,\n",
    "                      \"pred\": y_pred})\n",
    "(ggplot(assump, aes(x = \"pred\", y = \"errors\")) + \n",
    " geom_point() + \n",
    " theme_minimal() + \n",
    " geom_hline(yintercept = 0, linetype = \"dashed\", size = 1, color = \"red\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Homoskedasticity\n",
    "We assess Homoskedasticity using the same plot (remember *homo* = same, *hetero* = different; *skedasticity* refers to the variance of the errors). Looking at this residual plot, are there some areas along the x-axis where errors are huge, and others where they are small? We don't need it to be exactly the same, but are there any noticeable patterns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(ggplot(assump, aes(x = \"pred\", y = \"errors\")) + \n",
    " geom_point() + \n",
    " theme_minimal() + \n",
    " geom_hline(yintercept = 0, linetype = \"dashed\", size = 1, color = \"red\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normality\n",
    "\n",
    "Normality doesnt really impact prediction, in fact many argue it doesnt even impact inference (p-values/confidence intervals). So we won't dwell on it here. Here's code to check it using something called a QQ (Quantile-Quantile plot). We want to see whether there are large deviations from the red diagonal line (small deviations are expected at the two ends). [More on Normality](https://www.statsmodels.org/stable/generated/statsmodels.graphics.gofplots.qqplot.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normally (pun intended) we won't check this\n",
    "(ggplot(assump, aes(sample = \"errors\")) + \n",
    "stat_qq() + theme_minimal() + geom_abline(intercept = 0,\n",
    "                                          slope = np.std(assump[\"errors\"]),\n",
    "                                          color = \"red\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## What IS non-linear?\n",
    "\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=1nFuP_hDz42UMUk7_Z04IW-mBDuIq3YOV\" alt=\"Q\" width = \"800\"/>\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=1er2ygHzAXt3GAOz8zjIMU5R5vQuLqBf1\" alt=\"Q\" width = \"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What IS Heteroskedastic?\n",
    "Linear Regression assumes *homo*skedasticity meaning the variance is the same across all predicted values of the model.\n",
    "\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=1AXb9fz7Ui-JeMvs963OK_88Dh3XD0bWX\" alt=\"Q\" width = \"800\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients = pd.DataFrame({\"Coef\": pipe.named_steps['linearregression'].coef_, # grab array of coefficients\n",
    "                            \"Name\": predictors})\n",
    "intercept = pd.DataFrame({\"Coef\": pipe.named_steps['linearregression'].intercept_, # grab intercept\n",
    "                                   \"Name\": \"intercept\"},\n",
    "                                   index = [coefficients.shape[0]]) # since this is only 1 row, assign row a row index\n",
    "\n",
    "coefficents_all = pd.concat([coefficients,intercept])\n",
    "coefficents_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beyonce Worked Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and Clean Data\n",
    "b = pd.read_csv(\"https://raw.githubusercontent.com/cmparlettpelleriti/CPSC392ParlettPelleriti/master/Data/Beyonce_data.csv\")\n",
    "b.head()\n",
    "\n",
    "\n",
    "# Separate X and y\n",
    "# print(b.columns)\n",
    "\n",
    "predictors = [\"loudness\", \"speechiness\",\n",
    "              \"acousticness\", \"instrumentalness\", \"liveness\", \"valence\", \"mode\"]\n",
    "contin = [\"loudness\", \"speechiness\",\n",
    "              \"acousticness\", \"instrumentalness\", \"liveness\", \"valence\"]\n",
    "\n",
    "\n",
    "\n",
    "# create empty model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# fit\n",
    "\n",
    "\n",
    "\n",
    "# predict\n",
    "\n",
    "\n",
    "\n",
    "# assess\n",
    "\n",
    "\n",
    "\n",
    "# assump\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classwork (In Your Groups)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression Simulation\n",
    "\n",
    "Sometimes in this class, we'll run a **simulation** to see how our models perform in different scenarios. This helps us learn more about how the model works. Below is a function `linear_simulation()` that \n",
    "\n",
    "1. Generates fake data about cats' weights and lengths\n",
    "2. Fits a Linear Regression Model\n",
    "3. Grabs the coefficients\n",
    "4. Returns the data and Coefficients for us to look at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_simulation(n = 100, trueCoef = 0.04, intercept = 0.2, error_sd = 1):\n",
    "    \n",
    "    # 1. Generates fake data about cats' weights and lengths \n",
    "    # generate random data for cat length that follows a standard normal distribution\n",
    "    z_length = np.random.normal(loc = 0, scale = 1, size = n)\n",
    "    weight = intercept + z_length* trueCoef + np.random.normal(loc = 0, scale = error_sd, size = n)\n",
    "    # weight = intercept + length*coefficient + random error\n",
    "    \n",
    "    cats = pd.DataFrame({\"length\": z_length, \"weight\": weight})\n",
    "   \n",
    "\n",
    "\n",
    "    # 2. Fits a Linear Regression Model\n",
    "    features = [\"length\"]\n",
    "    X = cats[features]\n",
    "    y = cats[[\"weight\"]] #if you don't have the extra brackets, y will be a series instead of an array and throw an error\n",
    "\n",
    "    # run a linear regression\n",
    "    z = make_column_transformer((StandardScaler(), [\"length\"]),\n",
    "                                remainder = \"passthrough\")\n",
    "    \n",
    "    lr = LinearRegression()\n",
    "\n",
    "    pipe = Pipeline([\n",
    "        (\"z\", z),\n",
    "        (\"model\", lr)\n",
    "    ])\n",
    "\n",
    "    # fit the linear regression\n",
    "\n",
    "    pipe.fit(X,y)\n",
    " \n",
    "    \n",
    "    # 3. Grabs the coefficients\n",
    "    coef = pd.DataFrame({\"Coef\": pipe.named_steps[\"model\"].coef_[0], \"Names\": \"length\"}, index = [0])\n",
    "    inter = pd.DataFrame({\"Coef\": pipe.named_steps[\"model\"].intercept_[0], \"Names\": \"intercept\"}, index = [coef.shape[0]])\n",
    "    coef_all = pd.concat([coef,inter])\n",
    "\n",
    "\n",
    "    # 4. Returns the data and Coefficients for us to look at\n",
    "    return({\"coef\": coef_all, \"data\": cats})\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can run this simulation 100's of times.\n",
    "\n",
    "- `n` is the number of samples in each fake dataset\n",
    "- `trueCoef` is the true coefficient for cat length\n",
    "- `intercept` is the true intercept for the model\n",
    "- `error_sd` tells us how spread out the data is around the regression line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--- play around with these numbers-------\n",
    "n = 100\n",
    "trueCoef = 0.45 # don't change\n",
    "intercept = 6 # don't change\n",
    "error_sd = 1\n",
    "#-----------------------------------------\n",
    "\n",
    "#run regression simulation 500 times\n",
    "iWouldRun500Regressions = [linear_simulation(n = n, trueCoef = trueCoef, intercept = intercept, error_sd = error_sd) for x in range(0,500)]\n",
    "\n",
    "# grab coefficients from 500 simulations\n",
    "coef_df = pd.concat([x[\"coef\"] for x in iWouldRun500Regressions])\n",
    "\n",
    "# grab coefficients from 500 simulations\n",
    "data_df = pd.concat([x[\"data\"] for x in iWouldRun500Regressions])\n",
    "\n",
    "# number simulations 0:499\n",
    "data_df[\"simulation_no\"] = sorted(list(range(0,500))*n)\n",
    "coef_df[\"simulation_no\"] = sorted(list(range(0,500))*2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's Explore!\n",
    "\n",
    "Now that we've run a bunch of simulations with the SAME true coefficient and intercept (but different random samples), let's look at the results of our 500 regression models.\n",
    "\n",
    "\n",
    "First, let's just make some scatter plots to see some of the simulations. Notice how similar or different the simulations are from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_plot = 9\n",
    "\n",
    "chosen_datasets = data_df[\"simulation_no\"] < n_plot\n",
    "\n",
    "(ggplot(data_df.loc[chosen_datasets], aes(x = \"length\", y = \"weight\", color = \"factor(simulation_no)\")) +\n",
    "geom_point() +\n",
    "facet_wrap(\"~simulation_no\") +\n",
    "theme_minimal() +\n",
    "labs(color = \"Simulation Number\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the coefficient values from all the linear regressions we ran."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot legnth coef values and mean length coef value (red line)----\n",
    "coef_only = coef_df[\"Names\"] == \"length\"\n",
    "\n",
    "\n",
    "(ggplot(coef_df.loc[coef_only], aes(x = \"Coef\")) + \n",
    "geom_histogram(color = \"black\") +\n",
    "geom_vline(xintercept = coef_df.loc[coef_only, \"Coef\"].mean(), color = \"red\", linetype = \"dashed\", size = 2) +\n",
    "labs(title = \"Length Coefficient Values Across 500 Simulations\") +\n",
    "theme_minimal())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The mean coefficient for length across the 500 simulations is: \" + str(coef_df.loc[coef_only, \"Coef\"].mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Question*\n",
    "\n",
    "Look at the different values you got for the coefficient of length. We set the TRUE coefficient value to be 0.45, think about and describe how spread apart the estimates from our 500 regression models are. Does seeing how different our coefficient estimates can be *change* how you think about the coefficient estimates you get in regression models on real data?\n",
    "\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=1ghyQPx1N8dmU3MV4TrANvqNhGwnLni72\" alt=\"Q\" style=\"width: 200px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YOUR ANSWER HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Play with `n` and `error_sd`\n",
    "\n",
    "### *Question*\n",
    "Here are some suggestions:\n",
    "\n",
    "* Change `n`, the number of data points in each sample, to be very small (say 10), how does this change the results you saw?\n",
    "* Change `n`, the number of data points in each sample, to be very large (say 1,000), how does this change the results you saw?\n",
    "* Change the `error_sd` term, this is a measure of how much error is in the model. More error means that data is scattered tightly around the regression line, less error means that the data is scatters very loosely around the regression line. How does changing  `error_sd` change the results you originally saw?\n",
    "\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=1ghyQPx1N8dmU3MV4TrANvqNhGwnLni72\" alt=\"Q\" style=\"width: 200px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--- play around with these numbers-------\n",
    "n = 100\n",
    "trueCoef = 0.45 # don't change\n",
    "intercept = 6 # don't change\n",
    "error_sd = 1\n",
    "#-----------------------------------------\n",
    "\n",
    "#run regression simulation 500 times\n",
    "iWouldRun500More = [linear_simulation(n = n, trueCoef = trueCoef, intercept = intercept, error_sd = error_sd) for x in range(0,500)]\n",
    "\n",
    "# grab coefficients from 500 simulations\n",
    "coef_df = pd.concat([x[\"coef\"] for x in iWouldRun500More])\n",
    "\n",
    "# grab coefficients from 500 simulations\n",
    "data_df = pd.concat([x[\"data\"] for x in iWouldRun500More])\n",
    "\n",
    "# number simulations 0:499\n",
    "data_df[\"simulation_no\"] = sorted(list(range(0,500))*n)\n",
    "coef_df[\"simulation_no\"] = sorted(list(range(0,500))*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot some data sets\n",
    "n_plot = 9\n",
    "\n",
    "chosen_datasets = data_df[\"simulation_no\"] < n_plot\n",
    "\n",
    "(ggplot(data_df.loc[chosen_datasets], aes(x = \"length\", y = \"weight\", color = \"factor(simulation_no)\")) +\n",
    "geom_point() +\n",
    "facet_wrap(\"~simulation_no\") +\n",
    "theme_minimal() +\n",
    "labs(color = \"Simulation Number\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot legnth coef values and mean length coef value (red line)----\n",
    "coef_only = coef_df[\"Names\"] == \"length\"\n",
    "\n",
    "\n",
    "(ggplot(coef_df.loc[coef_only], aes(x = \"Coef\")) + \n",
    "geom_histogram(color = \"black\") +\n",
    "geom_vline(xintercept = coef_df.loc[coef_only, \"Coef\"].mean(), color = \"red\", linetype = \"dashed\", size = 2) +\n",
    "labs(title = \"Length Coefficient Values Across 500 Simulations\") +\n",
    "theme_minimal())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Question*\n",
    "Based on what you saw with the coefficients, do you expect Model performance metrics (like MSE, MAE, MAPE, or R2) to always be *perfect* estimates of how well the model is doing?\n",
    "\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=1ghyQPx1N8dmU3MV4TrANvqNhGwnLni72\" alt=\"Q\" style=\"width: 200px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpreting Linear Regression Coefficients\n",
    "\n",
    "While sometimes we just want the predictions from a linear regression model, we often will be asked to interpret the coefficients as well.\n",
    "\n",
    "Build a Linear Regression using the [Wine Data](https://raw.githubusercontent.com/cmparlettpelleriti/CPSC392ParlettPelleriti/master/Data/wineLARGE.csv). Print out a dataframe of the coefficients.\n",
    "\n",
    "### *Question*\n",
    "\n",
    "* Do you think the assumption of linearity is valid for this model?\n",
    "* How will a 1 standard deviation increase in `fixed.acidity` change the predicted `alcohol`?\n",
    "* What does the intercept represent?\n",
    "* If we took another random sample of wines from the same population, how do you expect the coefficients from the model would/could change?\n",
    "\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=1ghyQPx1N8dmU3MV4TrANvqNhGwnLni72\" alt=\"Q\" width = 200px/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.read_csv(\"https://raw.githubusercontent.com/cmparlettpelleriti/CPSC392ParlettPelleriti/master/Data/wineLARGE.csv\")\n",
    "\n",
    "predictors = ['fixed.acidity', 'volatile.acidity', 'citric.acid', 'residual.sugar',\n",
    "       'chlorides', 'free.sulfur.dioxide', 'total.sulfur.dioxide', 'density',\n",
    "       'pH', 'sulphates']\n",
    "\n",
    "##############################################\n",
    "\n",
    "#get rid of missing values\n",
    "\n",
    "\n",
    "# X and y\n",
    "\n",
    "\n",
    "# z score predictors\n",
    "\n",
    "# create regression\n",
    "\n",
    "\n",
    "# fit model\n",
    "\n",
    "\n",
    "\n",
    "##############################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "# print out table of coefficients\n",
    "\n",
    "##############################################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Violations of Linearity\n",
    "\n",
    "For some data exploration, use the first cell (`#nonLinReg`) to fit a model on **non linear data** meaning they violate the assumption of linearity. Use the second cell (`#LinReg`) to to fit a model on **linear** data. For both, create a plot of:\n",
    "\n",
    "* the predicted values vs the error (aka the residual plot)\n",
    "\n",
    "\n",
    "### *Question*\n",
    "\n",
    "* Compare patterns you see in the data that does *not* violate the assumption of linearity vs. the data that does. What's different?\n",
    "\n",
    "* What are some consequenses of violating the assumption of linearity?\n",
    "\n",
    "* if we used a linear regression to make predictions for the non-linear data, are there some ranges of `x` for which we'd *consistently* predict too high? are there some ranges of `x` for which we'd *consistently* predict too low?\n",
    "\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=1ghyQPx1N8dmU3MV4TrANvqNhGwnLni72\" alt=\"Q\" width = 200px/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nonLinReg\n",
    "\n",
    "df_nonlin = pd.read_csv(\"https://raw.githubusercontent.com/cmparlettpelleriti/CPSC392ParlettPelleriti/master/Data/06_nonlin.csv\")\n",
    "\n",
    "X = df_nonlin[[\"x\"]]\n",
    "y = df_nonlin[\"y\"]\n",
    "\n",
    "# z score\n",
    "\n",
    "\n",
    "# empty model\n",
    "\n",
    "\n",
    "# fit\n",
    "\n",
    "\n",
    "# predict\n",
    "\n",
    "\n",
    "# prediction and error data frame\n",
    "\n",
    "# residual plot\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LinReg \n",
    "df_lin = pd.read_csv(\"https://raw.githubusercontent.com/cmparlettpelleriti/CPSC392ParlettPelleriti/master/Data/06_lin.csv\")\n",
    "\n",
    "# X and y\n",
    "\n",
    "\n",
    "# z score\n",
    "\n",
    "# empty model\n",
    "\n",
    "\n",
    "# fit\n",
    "\n",
    "\n",
    "# predict\n",
    "\n",
    "# prediction and error data frame\n",
    "\n",
    "\n",
    "# residual plot\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
